# RAG Embedding Model Migration Challenge

## Overview
This project demonstrates a zero-downtime migration strategy for a production RAG (Retrieval Augmented Generation) system. The goal is to upgrade the embedding model from the legacy `textembedding-gecko@001` to the newer `text-embedding-005` without impacting the live application.

The process involves deploying a sample application, running a background data migration to create new embeddings in parallel, and finally, "flipping a switch" at the application level to use the new model and data.

## Core Components
*   **Cloud Function (`main.py`):** A small HTTP-triggered function that acts as our sample application. It takes a search term, creates an embedding, and queries a database for the most similar results.
*   **Cloud SQL Database:** A PostgreSQL instance with the `pgvector` extension, used to store amenities data and their corresponding vector embeddings. This is provisioned by the prerequisite Jump Start Solution.
*   **Migration Script (`migrate_embeddings.py`):** A Python script that connects to the database, reads the data, generates new embeddings using the `text-embedding-005` model, and saves them to a new column.

## Migration Strategy
The migration is performed using a "dual-write" or parallel backfilling strategy to ensure zero downtime:
1.  A new column (`embedding_005`) is added to the live `amenities` table. The original `embedding` column is left untouched.
2.  The `migrate_embeddings.py` script runs in the background, populating this new column with embeddings generated by the `text-embedding-005` model.
3.  Throughout this process, the live application continues to run, querying against the original `embedding` column without interruption.
4.  Once the backfilling is complete, the application is re-deployed with one minor change: it now queries against the new `embedding_005` column. This switch is instantaneous.

## How to Replicate This Challenge

### 1. Prerequisite: Deploy Google's RAG JSS
Before you begin, deploy the "Generative AI RAG" Jump Start Solution from the Google Cloud Marketplace into a development project. This will set up the necessary Cloud SQL database and initial data.
- **Link:** [https://console.cloud.google.com/products/solutions/details/generative-ai-rag](https://console.cloud.google.com/products/solutions/details/generative-ai-rag)

After deployment, gather the following details from your GCP project:
- Service Account Email
- Cloud SQL Instance Connection Name
- Database Password Secret Name

### 2. Deploy the Initial Test Function
Deploy the Cloud Function pointing to the **old** embedding model. This simulates the "before" state.

```bash
gcloud functions deploy rag-jss-test-function \
    --gen2 \
    --region="us-central1" \
    --runtime=python312 \
    --source=./ \
    --entry-point=hello_http \
    --trigger-http \
    --allow-unauthenticated \
    --service-account="[YOUR_SERVICE_ACCOUNT_EMAIL]" \
    --set-env-vars="DB_USER=retrieval-service,DB_NAME=assistantdemo,EMBEDDING_MODEL=textembedding-gecko@001,INSTANCE_CONNECTION_NAME=[YOUR_INSTANCE_CONNECTION_NAME]" \
    --set-secrets="DB_PASS=[YOUR_DB_SECRET_NAME]:latest"
```
**Note:** At this stage, testing the function is expected to fail with a permission error related to the `gecko` model, as described in the challenge.

### 3. Run the Data Migration
Execute the migration script to populate the database with new embeddings. This script will add the `embedding_005` column and fill it.

```bash
DB_PASS=$(gcloud secrets versions access latest --secret="[YOUR_DB_SECRET_NAME]") \
INSTANCE_CONNECTION_NAME="[YOUR_INSTANCE_CONNECTION_NAME]" \
DB_USER="retrieval-service" \
DB_NAME="assistantdemo" \
GCP_PROJECT_ID="[YOUR_GCP_PROJECT_ID]" \
GCP_LOCATION="us-central1" \
python migrate_embeddings.py
```

### 4. Deploy the Upgraded Function
With the data migrated, re-deploy the function. The only change is the `EMBEDDING_MODEL` environment variable, which now points to the new model. The function's code will automatically use the corresponding `embedding_005` column.

```bash
gcloud functions deploy rag-jss-test-function \
    --gen2 \
    --region="us-central1" \
    --runtime=python312 \
    --source=./ \
    --entry-point=hello_http \
    --trigger-http \
    --allow-unauthenticated \
    --service-account="[YOUR_SERVICE_ACCOUNT_EMAIL]" \
    --set-env-vars="DB_USER=retrieval-service,DB_NAME=assistantdemo,EMBEDDING_MODEL=text-embedding-005,INSTANCE_CONNECTION_NAME=[YOUR_INSTANCE_CONNECTION_NAME]" \
    --set-secrets="DB_PASS=[YOUR_DB_SECRET_NAME]:latest"
```

### 5. Validate the Migration
Test the final, upgraded function. You should receive a successful JSON response.

```bash
curl -m 70 -X POST "[YOUR_FUNCTION_TRIGGER_URL]" \
    -H "Content-Type: application/json" \
    -d '{"name": "restaurants"}'
```

Expected Success Output:
```json
{"results":[{"description":"...","name":"Bourbon Pub"},{"description":"...","name":"Mission Bar & Grill"},{"description":"...","name":"Starbucks"}]}
```

## Project Structure
```
rag-jss-migration-challenge/
│
├── main.py              # The Cloud Function application code.
├── migrate_embeddings.py # The script to migrate data to the new embedding model.
└── requirements.txt     # Python dependencies.
```

## Dependencies
- functions-framework==3.*
- pg8000
- cloud-sql-python-connector
- Flask
- SQLAlchemy
- google-cloud-aiplatform>=1.38.0 